{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/raghav.arora/miniconda3/envs/habitat/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "import habitat\n",
    "from habitat.utils.visualizations.utils import images_to_video\n",
    "from habitat.config.default import patch_config\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from hydra.experimental import compose, initialize\n",
    "from habitat.config.default_structured_configs import register_hydra_plugin\n",
    "from habitat_baselines.config.default_structured_configs import (\n",
    "    HabitatBaselinesConfigPlugin,\n",
    ")\n",
    "\n",
    "register_hydra_plugin(HabitatBaselinesConfigPlugin)\n",
    "\n",
    "hydra.initialize(\n",
    "    config_path=\"habitat-lab/habitat/config/\",\n",
    "    job_name=\"try\",\n",
    "    version_base=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = 'benchmark/multi_agent/hssd_spot_human_social_nav.yaml'\n",
    "cfg = hydra.compose(config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = patch_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 16:33:02,829 Initializing dataset RearrangeDataset-v0\n",
      "2023-11-16 16:33:06,630 initializing sim RearrangeSim-v0\n",
      "[16:33:09:906019]:[Warning]:[Sim] Simulator.cpp(533)::instanceStageForSceneAttributes : The active scene does not contain semantic annotations : activeSemanticSceneID_ = 0\n",
      "[16:33:11:935862]:[Warning]:[Metadata] AttributesManagerBase.h(346)::loadAllTemplatesFromPathAndExt : <Object Template> : Parsing `object_config.json` files : Cannot find `data/objects/amazon_berkeley/configs/` as directory or `data/objects/amazon_berkeley/configs/.object_config.json` as config file, so template load failed.\n",
      "[16:33:11:935921]:[Warning]:[Metadata] AttributesManagerBase.h(346)::loadAllTemplatesFromPathAndExt : <Object Template> : Parsing `object_config.json` files : Cannot find `data/objects/google_object_dataset/configs/` as directory or `data/objects/google_object_dataset/configs/.object_config.json` as config file, so template load failed.\n",
      "2023-11-16 16:33:11,937 Initializing task RearrangePddlSocialNavTask-v0\n",
      "/home2/raghav.arora/miniconda3/envs/habitat/lib/python3.9/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 510.108.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "Reached here\n",
      "Action Space:  None\n",
      "I should reach here too\n",
      "Action Space:  ['agent_0_base_velocity', 'agent_1_base_velocity', 'agent_1_oracle_nav_action', 'agent_1_oracle_nav_randcoord_action', 'agent_1_pddl_apply_action', 'agent_1_rearrange_stop']\n",
      "Finally\n",
      "Dict(agent_0_base_velocity:Dict(agent_0_base_vel:Box(-20.0, 20.0, (2,), float32)), agent_1_base_velocity:Dict(agent_1_base_vel:Box(-20.0, 20.0, (2,), float32)), agent_1_oracle_nav_action:Dict(agent_1_oracle_nav_action:Box(-3.4028235e+38, 3.4028235e+38, (1,), float32)), agent_1_oracle_nav_randcoord_action:Dict(agent_1_oracle_nav_randcoord_action:Box(-3.4028235e+38, 3.4028235e+38, (1,), float32)), agent_1_pddl_apply_action:Dict(agent_1_pddl_action:Box(-3.4028235e+38, 3.4028235e+38, (18,), float32)), agent_1_rearrange_stop:EmptySpace())\n"
     ]
    }
   ],
   "source": [
    "env = habitat.gym.make_gym_from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_0_articulated_agent_arm_depth',\n",
       " 'agent_0_articulated_agent_arm_panoptic',\n",
       " 'agent_0_articulated_agent_arm_rgb',\n",
       " 'agent_0_ee_pos',\n",
       " 'agent_0_goal_to_agent_gps_compass',\n",
       " 'agent_0_has_finished_oracle_nav',\n",
       " 'agent_0_head_depth',\n",
       " 'agent_0_head_rgb',\n",
       " 'agent_0_humanoid_detector_sensor',\n",
       " 'agent_0_humanoid_joint_sensor',\n",
       " 'agent_0_is_holding',\n",
       " 'agent_0_joint',\n",
       " 'agent_0_localization_sensor',\n",
       " 'agent_0_obj_goal_gps_compass',\n",
       " 'agent_0_obj_goal_sensor',\n",
       " 'agent_0_obj_start_gps_compass',\n",
       " 'agent_0_obj_start_sensor',\n",
       " 'agent_0_other_agent_gps',\n",
       " 'agent_0_relative_resting_position',\n",
       " 'agent_1_agents_within_threshold',\n",
       " 'agent_1_ee_pos',\n",
       " 'agent_1_goal_to_agent_gps_compass',\n",
       " 'agent_1_has_finished_oracle_nav',\n",
       " 'agent_1_head_depth',\n",
       " 'agent_1_head_rgb',\n",
       " 'agent_1_humanoid_detector_sensor',\n",
       " 'agent_1_humanoid_joint_sensor',\n",
       " 'agent_1_is_holding',\n",
       " 'agent_1_joint',\n",
       " 'agent_1_localization_sensor',\n",
       " 'agent_1_obj_goal_gps_compass',\n",
       " 'agent_1_obj_goal_sensor',\n",
       " 'agent_1_obj_start_gps_compass',\n",
       " 'agent_1_obj_start_sensor',\n",
       " 'agent_1_other_agent_gps',\n",
       " 'agent_1_relative_resting_position']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 16:52:56,617 Video created: raghav/social0.mp4\n",
      "100%|██████████| 750/750 [00:00<00:00, 976.75it/s] \n",
      "2023-11-16 16:52:57,414 Video created: raghav/social1.mp4\n",
      "100%|██████████| 750/750 [00:01<00:00, 652.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "observations = env.reset()\n",
    "base_vel_x_0 = 0\n",
    "base_vel_y_0 = 0\n",
    "base_vel_x_1 = 15\n",
    "base_vel_y_1 = 0\n",
    "\n",
    "action = np.zeros(25, dtype=np.float32)\n",
    "action[0] = base_vel_x_0\n",
    "action[1] = base_vel_y_0\n",
    "action[2] = base_vel_x_1\n",
    "action[3] = base_vel_y_1\n",
    "\n",
    "done = False\n",
    "images0 = []\n",
    "images1 = []\n",
    "while not done:\n",
    "    observations, reward, done, info = env.step(action)\n",
    "    # print(list(observations.keys()))\n",
    "    action = env.action_space.sample()\n",
    "    if 'agent_0_humanoid_detector_sensor' in observations and observations['agent_0_humanoid_detector_sensor'] is not None:\n",
    "        action[0] = -base_vel_x_0\n",
    "        action[1] = base_vel_y_0\n",
    "\n",
    "    else:\n",
    "        action[0] = base_vel_x_0\n",
    "        action[1] = base_vel_y_0\n",
    "    # if 'agent_1_humanoid_detector_sensor' in observations and observations['agent_1_humanoid_detector_sensor'] is not None:\n",
    "    #     action[2] = -base_vel_x_1  # Reverse the x velocity\n",
    "    #     action[3] = base_vel_y_1   # Keep the y velocity same\n",
    "    # else:\n",
    "    #     action[2] = base_vel_x_1\n",
    "    #     action[3] = base_vel_y_1\n",
    "\n",
    "    images0.append(observations['agent_0_head_rgb'])\n",
    "    images1.append(observations['agent_1_head_rgb'])\n",
    "\n",
    "from habitat.utils.visualizations.utils import images_to_video\n",
    "images_to_video(images0, 'raghav', \"social0\")\n",
    "images_to_video(images1, 'raghav', \"social1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function habitat.utils.visualizations.maps.get_topdown_map(pathfinder, height: float, map_resolution: int = 1024, draw_border: bool = True, meters_per_pixel: Optional[float] = None) -> numpy.ndarray>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from habitat.utils.visualizations import maps\n",
    "maps.get_topdown_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_steps = 0\n",
    "images = []\n",
    "observations = env.reset()\n",
    "terminal = False\n",
    "observations, reward, terminal, info = env.step(\n",
    "    env.action_space.sample()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = habitat.gym.make_gym_from_config(config)\n",
    "print(\"Environment creation successful\")\n",
    "observations = env.reset()  # noqa: F841\n",
    "\n",
    "print(\"Agent acting inside environment.\")\n",
    "count_steps = 0\n",
    "terminal = False\n",
    "images = []\n",
    "print(\"Agent stepping around inside environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not terminal:\n",
    "    observations, reward, terminal, info = env.step(\n",
    "        env.action_space.sample()\n",
    "    )  # noqa: F841\n",
    "    count_steps += 1\n",
    "    \n",
    "    print(observations.keys())\n",
    "    im = observations[\"head_rgb\"]\n",
    "    images.append(im)\n",
    "\n",
    "    print(info)\n",
    "    images_to_video(images, 'raghav', \"trajectory\")\n",
    "    print(\"Episode finished after {} steps.\".format(count_steps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
